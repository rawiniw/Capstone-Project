{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(map(pd.read_csv, \n",
    "                   ['walmart.csv', \n",
    "                    'target.csv',\n",
    "                    'amazon.csv',\n",
    "                    'costco.csv',\n",
    "                    'kroger.csv']),ignore_index = True)\n",
    "\n",
    "df.loc[:,'tokens_final'] = \\\n",
    "df.loc[:,'tokens_final'].apply(lambda x: literal_eval(x))\n",
    "\n",
    "def replace_in_list(lis, old, new):\n",
    "    for i in range(len(lis)):\n",
    "        if lis[i] == old:\n",
    "            lis[i] = new\n",
    "    return(lis)\n",
    "\n",
    "df['tokens_final'] = \\\n",
    "df['tokens_final'].map(lambda x: replace_in_list(x,\"employee\", \"associate\"))\n",
    "\n",
    "df['tokens_final'] = \\\n",
    "df['tokens_final'].map(lambda x: replace_in_list(x,\"guest\", \"customer\"))\n",
    "\n",
    "df['tokens_final'] = \\\n",
    "df['tokens_final'].map(lambda x: replace_in_list(x,\"consumer\", \"customer\"))\n",
    "\n",
    "remove_words =['performance','officer','value','award','amount',\n",
    "               'cash','chairman','vice','option','president',\n",
    "               'base','inc.','grant','voting','election','unit',\n",
    "               'audit','benefit','date','service','management',\n",
    "               'include','number','name','person','proposal',\n",
    "               'section','report','cost','receive','pension',\n",
    "               'rate','interest','fuel','rate','serve','sale','pension']\n",
    "\n",
    "df[\"tokens_final\"] = \\\n",
    "    df[\"tokens_final\"].map(lambda x: \\\n",
    "    [word for word in x if word.lower() not in remove_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>company</th>\n",
       "      <th>tokens_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[street, website, www.walmartstores.com, notic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[wal-mart, store, street, website, www.walmart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[nonqualified, compensation, potential, paymen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[compensation, store, compensation, amend, jan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[nominee, statement, company, ratification, ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>2019</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>[company, termination, cause, treatment, provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>2019</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>[purpose, approve, company, provide, provision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>2019</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>[security, restriction, represent, book, accou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>2019</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>[case, jurisdiction, approve, discretion, prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>2019</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>[company, extent, deems, discretion, purpose, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3715 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  company                                       tokens_final\n",
       "0     2010  Walmart  [street, website, www.walmartstores.com, notic...\n",
       "1     2010  Walmart  [wal-mart, store, street, website, www.walmart...\n",
       "2     2010  Walmart  [nonqualified, compensation, potential, paymen...\n",
       "3     2010  Walmart  [compensation, store, compensation, amend, jan...\n",
       "4     2010  Walmart  [nominee, statement, company, ratification, ap...\n",
       "...    ...      ...                                                ...\n",
       "3710  2019   Kroger  [company, termination, cause, treatment, provi...\n",
       "3711  2019   Kroger  [purpose, approve, company, provide, provision...\n",
       "3712  2019   Kroger  [security, restriction, represent, book, accou...\n",
       "3713  2019   Kroger  [case, jurisdiction, approve, discretion, prov...\n",
       "3714  2019   Kroger  [company, extent, deems, discretion, purpose, ...\n",
       "\n",
       "[3715 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir(\"temp_text\")\n",
    "\n",
    "companies = df[\"company\"].drop_duplicates().values\n",
    "\n",
    "for company in companies:\n",
    "    os.mkdir(\"temp_text\\\\\" + company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    company = row[\"company\"]\n",
    "    year = row[\"year\"]\n",
    "    text = ' '.join(row[\"tokens_final\"])\n",
    "    \n",
    "    with open(f\"temp_text\\\\{company}\\\\{year}_{company}_{index}.txt\", 'w', encoding='utf8') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gensim\n",
    "\n",
    "def iter_documents(top_directory):\n",
    "    \"\"\"Iterate over all documents, yielding a document (=list of utf8 tokens) at a time.\"\"\"\n",
    "    for root, dirs, files in os.walk(top_directory):\n",
    "        for file in filter(lambda file: file.endswith('.txt'), files):\n",
    "            document = open(os.path.join(root, file), encoding='utf8').read() # read the entire document, as one big string\n",
    "            yield gensim.utils.tokenize(document, lower=True) # or whatever tokenization suits you\n",
    "\n",
    "class MyCorpus(object):\n",
    "    def __init__(self, top_dir):\n",
    "        self.top_dir = top_dir\n",
    "        self.dictionary = gensim.corpora.Dictionary(iter_documents(top_dir))\n",
    "        self.dictionary.filter_extremes(no_below=1, keep_n=30000) # check API docs for pruning params\n",
    "\n",
    "    def __iter__(self):\n",
    "        for tokens in iter_documents(self.top_dir):\n",
    "            yield self.dictionary.doc2bow(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart_corpus = MyCorpus('temp_text/walmart')\n",
    "amazon_corpus  = MyCorpus('temp_text/amazon')\n",
    "costco_corpus  = MyCorpus('temp_text/costco')\n",
    "target_corpus  = MyCorpus('temp_text/target')\n",
    "kroger_corpus  = MyCorpus('temp_text/kroger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "ntopic = 10\n",
    "\n",
    "lda_walmart = LdaModel(walmart_corpus, num_topics=ntopic, id2word=walmart_corpus.dictionary)\n",
    "lda_amazon  = LdaModel(amazon_corpus , num_topics=ntopic, id2word=amazon_corpus.dictionary)\n",
    "lda_costco  = LdaModel(costco_corpus , num_topics=ntopic, id2word=costco_corpus.dictionary)\n",
    "lda_target  = LdaModel(target_corpus , num_topics=ntopic, id2word=target_corpus.dictionary)\n",
    "lda_kroger  = LdaModel(kroger_corpus , num_topics=ntopic, id2word=kroger_corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [(\"Walmart\", walmart_corpus, lda_walmart), \n",
    "         (\"Amazon\", amazon_corpus, lda_amazon),\n",
    "         (\"Costco\", costco_corpus, lda_costco), \n",
    "         (\"Target\", target_corpus, lda_target), \n",
    "         (\"Kroger\", kroger_corpus, lda_kroger)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "names_prod = list(itertools.product(names, names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def average_topic(flat_list):\n",
    "\n",
    "    d = OrderedDict()\n",
    "    for prob, topic in flat_list:\n",
    "        d.setdefault(topic, []).append(prob)\n",
    "\n",
    "    d = [(sum(v) / len(v), k) for k, v in d.items()]\n",
    "    \n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('incentive', 0.02142479), ('defer', 0.021224383), ('cngc', 0.014651998), ('program', 0.009155399), ('income', 0.0088225305), ('payment', 0.008607056), ('result', 0.008327849), ('contribution', 0.008182822), ('account', 0.007996664), ('goal', 0.0074817943)]\n",
      "\n",
      "[('incentive', 0.017756734), ('target', 0.011836097), ('goal', 0.009922712), ('equity', 0.009922202), ('accountant', 0.009170052), ('governance', 0.008469286), ('associate', 0.008039322), ('rule', 0.0077500935), ('risk', 0.0073270584), ('result', 0.0072643426)]\n",
      "\n",
      "[('payment', 0.015311355), ('employment', 0.011849031), ('business', 0.010751324), ('income', 0.009644408), ('incentive', 0.009532485), ('time', 0.009353391), ('agreement', 0.008744033), ('vest', 0.008499161), ('equity', 0.007924628), ('hold', 0.0073880786)]\n",
      "\n",
      "[('incentive', 0.014110572), ('member', 0.012632844), ('policy', 0.011758959), ('program', 0.01056016), ('associate', 0.0093910275), ('transaction', 0.008442447), ('material', 0.008108177), ('make', 0.007444198), ('measure', 0.0070826), ('cngc', 0.0069788857)]\n",
      "\n",
      "[('member', 0.013077271), ('column', 0.012435204), ('measure', 0.01236153), ('incentive', 0.011064288), ('goal', 0.010164914), ('governance', 0.00984039), ('income', 0.0070451363), ('currency', 0.007027786), ('rule', 0.0065876646), ('show', 0.0064300825)]\n",
      "\n",
      "[('material', 0.012803006), ('time', 0.011897937), ('associate', 0.011009221), ('measure', 0.009836259), ('business', 0.009555237), ('ownership', 0.00931056), ('make', 0.0081628645), ('rule', 0.007947175), ('income', 0.00634742), ('period', 0.005572941)]\n",
      "\n",
      "[('goal', 0.019316547), ('cngc', 0.018518798), ('member', 0.01278732), ('review', 0.012228778), ('governance', 0.012029474), ('incentive', 0.010484885), ('transaction', 0.009634004), ('equity', 0.008405318), ('policy', 0.0074389325), ('rule', 0.0072900765)]\n",
      "\n",
      "[('hold', 0.014949722), ('material', 0.0148309525), ('member', 0.012979955), ('business', 0.009475126), ('instruction', 0.008777956), ('nominee', 0.008652564), ('experience', 0.00769814), ('review', 0.007537112), ('information', 0.0071900804), ('transaction', 0.0065907394)]\n",
      "\n",
      "[('target', 0.017551143), ('incentive', 0.015589957), ('income', 0.009730569), ('program', 0.009660547), ('equity', 0.00948445), ('restrict', 0.008511101), ('business', 0.008161458), ('account', 0.00752858), ('information', 0.0073523945), ('compliance', 0.0072714286)]\n",
      "\n",
      "[('experience', 0.01741953), ('defer', 0.011716119), ('business', 0.010185008), ('incentive', 0.01014479), ('payment', 0.009297066), ('equity', 0.0089673335), ('risk', 0.008169925), ('make', 0.0078109056), ('governance', 0.0074676834), ('associate', 0.00720462)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(ntopic):\n",
    "    print(lda_walmart.show_topic(topicid=i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walmart model applied to Walmart documents\n",
      "[(0.4597179211639598, 0), (0.45101957516513824, 1), (0.46591635599475484, 2), (0.4539851728729459, 3), (0.47907849926864954, 4), (0.5195802708865324, 5), (0.5420506339043056, 6), (0.5447015820229624, 7), (0.5301722562034971, 8), (0.4870988519213508, 9)]\n",
      "\n",
      "Walmart model applied to Amazon documents\n",
      "[(0.1327859936425319, 0), (0.09570725506969861, 1), (0.11437531503970208, 2), (0.21399529271626047, 3), (0.16768148763415713, 4), (0.118088659318164, 5), (0.43415580976493, 6), (0.31699287521226677, 7), (0.1512126382088886, 8), (0.2313662926963669, 9)]\n",
      "\n",
      "Walmart model applied to Costco documents\n",
      "[(0.1514108526579877, 0), (0.1483152644231734, 1), (0.11793755789772725, 2), (0.21332072737345167, 3), (0.15815852240969738, 4), (0.16531541884966916, 5), (0.3547402023309245, 6), (0.2781293787574642, 7), (0.15612627776746435, 8), (0.33317492798267945, 9)]\n",
      "\n",
      "Walmart model applied to Target documents\n",
      "[(0.14421049265130872, 0), (0.148442068794178, 1), (0.17897535718815483, 2), (0.17106666058376807, 3), (0.10373811355931052, 4), (0.14637323293708643, 5), (0.293135232385799, 6), (0.29972444934314874, 7), (0.12448778516875628, 8), (0.26966153770996143, 9)]\n",
      "\n",
      "Walmart model applied to Kroger documents\n",
      "[(0.13302933392434343, 0), (0.15838957554559946, 1), (0.11485677904743243, 2), (0.16657646892178038, 3), (0.12301922512332393, 4), (0.12299286068149808, 5), (0.4133683927589028, 6), (0.18046738359250025, 7), (0.19735246557195812, 8), (0.21567588049406725, 9)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "for index, pair in enumerate(names_prod[:5]):\n",
    "    model_txt  = pair[0][0]\n",
    "    corpus_txt = pair[1][0]\n",
    "    \n",
    "    model  = pair[0][2]\n",
    "    corpus = pair[1][1]\n",
    "    \n",
    "    print(f\"{model_txt} model applied to {corpus_txt} documents\")\n",
    "    tag = [model.get_document_topics(item) for item in corpus]\n",
    "    tag = [tup[::-1] for tup in flatten(tag)]\n",
    "    \n",
    "    topic_avg = average_topic(tag)\n",
    "    topic_avg = sorted(topic_avg, key = lambda x: x[1])\n",
    "    \n",
    "    print(topic_avg)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
