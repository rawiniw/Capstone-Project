{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(map(pd.read_csv, \n",
    "                   ['walmart.csv', \n",
    "                    'target.csv',\n",
    "                    'amazon.csv',\n",
    "                    'costco.csv',\n",
    "                    'kroger.csv']),ignore_index = True)\n",
    "\n",
    "df.loc[:,'tokens_final'] = \\\n",
    "df.loc[:,'tokens_final'].apply(lambda x: literal_eval(x))\n",
    "\n",
    "def replace_in_list(lis, old, new):\n",
    "    for i in range(len(lis)):\n",
    "        if lis[i] == old:\n",
    "            lis[i] = new\n",
    "    return(lis)\n",
    "\n",
    "df['tokens_final'] = \\\n",
    "df['tokens_final'].map(lambda x: replace_in_list(x,\"employee\", \"associate\"))\n",
    "\n",
    "df['tokens_final'] = \\\n",
    "df['tokens_final'].map(lambda x: replace_in_list(x,\"guest\", \"customer\"))\n",
    "\n",
    "df['tokens_final'] = \\\n",
    "df['tokens_final'].map(lambda x: replace_in_list(x,\"consumer\", \"customer\"))\n",
    "\n",
    "remove_words =['performance','officer','value','award','amount',\n",
    "               'cash','chairman','vice','option','president',\n",
    "               'base','inc.','grant','voting','election','unit',\n",
    "               'audit','benefit','date','service','management',\n",
    "               'include','number','name','person','proposal',\n",
    "               'section','report','cost','receive','pension',\n",
    "               'rate','interest','fuel','rate','serve','sale','pension']\n",
    "\n",
    "df[\"tokens_final\"] = \\\n",
    "    df[\"tokens_final\"].map(lambda x: \\\n",
    "    [word for word in x if word.lower() not in remove_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>company</th>\n",
       "      <th>tokens_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[street, website, www.walmartstores.com, notic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[wal-mart, store, street, website, www.walmart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[nonqualified, compensation, potential, paymen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[compensation, store, compensation, amend, jan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>[nominee, statement, company, ratification, ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>2019</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>[company, termination, cause, treatment, provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>2019</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>[purpose, approve, company, provide, provision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>2019</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>[security, restriction, represent, book, accou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>2019</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>[case, jurisdiction, approve, discretion, prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>2019</td>\n",
       "      <td>Kroger</td>\n",
       "      <td>[company, extent, deems, discretion, purpose, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3715 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  company                                       tokens_final\n",
       "0     2010  Walmart  [street, website, www.walmartstores.com, notic...\n",
       "1     2010  Walmart  [wal-mart, store, street, website, www.walmart...\n",
       "2     2010  Walmart  [nonqualified, compensation, potential, paymen...\n",
       "3     2010  Walmart  [compensation, store, compensation, amend, jan...\n",
       "4     2010  Walmart  [nominee, statement, company, ratification, ap...\n",
       "...    ...      ...                                                ...\n",
       "3710  2019   Kroger  [company, termination, cause, treatment, provi...\n",
       "3711  2019   Kroger  [purpose, approve, company, provide, provision...\n",
       "3712  2019   Kroger  [security, restriction, represent, book, accou...\n",
       "3713  2019   Kroger  [case, jurisdiction, approve, discretion, prov...\n",
       "3714  2019   Kroger  [company, extent, deems, discretion, purpose, ...\n",
       "\n",
       "[3715 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran once to write files\n",
    "\n",
    "# import os\n",
    "# os.mkdir(\"temp_text\")\n",
    "\n",
    "# companies = df[\"company\"].drop_duplicates().values\n",
    "\n",
    "# for company in companies:\n",
    "#     os.mkdir(\"temp_text\\\\\" + company)\n",
    "    \n",
    "# for index, row in df.iterrows():\n",
    "#     company = row[\"company\"]\n",
    "#     year = row[\"year\"]\n",
    "#     text = ' '.join(row[\"tokens_final\"])\n",
    "    \n",
    "#     with open(f\"temp_text\\\\{company}\\\\{year}_{company}_{index}.txt\", 'w', encoding='utf8') as f:\n",
    "#         f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gensim\n",
    "\n",
    "def iter_documents(top_directory):\n",
    "    \"\"\"Iterate over all documents, yielding a document (=list of utf8 tokens) at a time.\"\"\"\n",
    "    for root, dirs, files in os.walk(top_directory):\n",
    "        for file in filter(lambda file: file.endswith('.txt'), files):\n",
    "            document = open(os.path.join(root, file), encoding='utf8').read() # read the entire document, as one big string\n",
    "            yield gensim.utils.tokenize(document, lower=True) # or whatever tokenization suits you\n",
    "\n",
    "class MyCorpus(object):\n",
    "    def __init__(self, top_dir):\n",
    "        self.top_dir = top_dir\n",
    "        self.dictionary = gensim.corpora.Dictionary(iter_documents(top_dir))\n",
    "        self.dictionary.filter_extremes(no_below=1, keep_n=30000) # check API docs for pruning params\n",
    "\n",
    "    def __iter__(self):\n",
    "        for tokens in iter_documents(self.top_dir):\n",
    "            yield self.dictionary.doc2bow(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart_corpus = MyCorpus('temp_text/walmart')\n",
    "amazon_corpus  = MyCorpus('temp_text/amazon')\n",
    "costco_corpus  = MyCorpus('temp_text/costco')\n",
    "target_corpus  = MyCorpus('temp_text/target')\n",
    "kroger_corpus  = MyCorpus('temp_text/kroger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "ntopic = 10\n",
    "\n",
    "lda_walmart = LdaModel(walmart_corpus, num_topics=ntopic, id2word=walmart_corpus.dictionary)\n",
    "lda_amazon  = LdaModel(amazon_corpus , num_topics=ntopic, id2word=amazon_corpus.dictionary)\n",
    "lda_costco  = LdaModel(costco_corpus , num_topics=ntopic, id2word=costco_corpus.dictionary)\n",
    "lda_target  = LdaModel(target_corpus , num_topics=ntopic, id2word=target_corpus.dictionary)\n",
    "lda_kroger  = LdaModel(kroger_corpus , num_topics=ntopic, id2word=kroger_corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [(\"Walmart\", walmart_corpus, lda_walmart), \n",
    "         (\"Amazon\", amazon_corpus, lda_amazon),\n",
    "         (\"Costco\", costco_corpus, lda_costco), \n",
    "         (\"Target\", target_corpus, lda_target), \n",
    "         (\"Kroger\", kroger_corpus, lda_kroger)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "names_prod = list(itertools.product(names, names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def average_topic(flat_list):\n",
    "\n",
    "    d = OrderedDict()\n",
    "    for prob, topic in flat_list:\n",
    "        d.setdefault(topic, []).append(prob)\n",
    "\n",
    "    d = [(sum(v) / len(v), k) for k, v in d.items()]\n",
    "    \n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   ('member', 0.020815318),\n",
      "    ('experience', 0.015948776),\n",
      "    ('cngc', 0.014865066),\n",
      "    ('business', 0.011187044),\n",
      "    ('incentive', 0.010436272),\n",
      "    ('corporation', 0.009863281),\n",
      "    ('review', 0.009304732),\n",
      "    ('governance', 0.009019247),\n",
      "    ('group', 0.008369606),\n",
      "    ('rule', 0.008257974)]\n",
      "\n",
      "[   ('column', 0.017674008),\n",
      "    ('equity', 0.0146302385),\n",
      "    ('incentive', 0.010269762),\n",
      "    ('payment', 0.009645595),\n",
      "    ('information', 0.00938826),\n",
      "    ('table', 0.008672465),\n",
      "    ('review', 0.0083433),\n",
      "    ('douglas', 0.008292766),\n",
      "    ('rule', 0.00827823),\n",
      "    ('market', 0.007920543)]\n",
      "\n",
      "[   ('transaction', 0.016856004),\n",
      "    ('member', 0.014321849),\n",
      "    ('review', 0.012210391),\n",
      "    ('policy', 0.011638354),\n",
      "    ('goal', 0.011564127),\n",
      "    ('incentive', 0.01017085),\n",
      "    ('cngc', 0.009424425),\n",
      "    ('accountant', 0.009326033),\n",
      "    ('recipient', 0.009256202),\n",
      "    ('target', 0.008195261)]\n",
      "\n",
      "[   ('transaction', 0.014363549),\n",
      "    ('business', 0.0126234),\n",
      "    ('material', 0.01241821),\n",
      "    ('associate', 0.00916168),\n",
      "    ('cngc', 0.008836774),\n",
      "    ('equity', 0.008449217),\n",
      "    ('defer', 0.0075979624),\n",
      "    ('rule', 0.0074918517),\n",
      "    ('time', 0.0074329074),\n",
      "    ('instruction', 0.0073637296)]\n",
      "\n",
      "[   ('defer', 0.020596625),\n",
      "    ('contribution', 0.0151858255),\n",
      "    ('equity', 0.012111226),\n",
      "    ('account', 0.011239773),\n",
      "    ('cmdc', 0.010454961),\n",
      "    ('governance', 0.009122334),\n",
      "    ('measure', 0.008379229),\n",
      "    ('incentive', 0.008206335),\n",
      "    ('program', 0.00796875),\n",
      "    ('participant', 0.007964951)]\n",
      "\n",
      "[   ('goal', 0.018108523),\n",
      "    ('incentive', 0.017790815),\n",
      "    ('program', 0.011521167),\n",
      "    ('target', 0.008758558),\n",
      "    ('result', 0.008614029),\n",
      "    ('cngc', 0.008110365),\n",
      "    ('restrict', 0.007969611),\n",
      "    ('payment', 0.007957374),\n",
      "    ('hold', 0.0075473674),\n",
      "    ('policy', 0.0074028987)]\n",
      "\n",
      "[   ('incentive', 0.017260043),\n",
      "    ('target', 0.0156668),\n",
      "    ('cngc', 0.013475682),\n",
      "    ('income', 0.012462263),\n",
      "    ('goal', 0.011397852),\n",
      "    ('payment', 0.009355652),\n",
      "    ('make', 0.007262844),\n",
      "    ('equity', 0.0072476),\n",
      "    ('period', 0.0069489065),\n",
      "    ('result', 0.0069342563)]\n",
      "\n",
      "[   ('target', 0.019368984),\n",
      "    ('incentive', 0.016363824),\n",
      "    ('goal', 0.015136152),\n",
      "    ('payment', 0.013675567),\n",
      "    ('equity', 0.013637951),\n",
      "    ('income', 0.012802228),\n",
      "    ('time', 0.012519759),\n",
      "    ('measure', 0.010892905),\n",
      "    ('show', 0.010300024),\n",
      "    ('period', 0.0084011415)]\n",
      "\n",
      "[   ('governance', 0.012236504),\n",
      "    ('risk', 0.011902815),\n",
      "    ('business', 0.011413673),\n",
      "    ('member', 0.010254936),\n",
      "    ('hold', 0.009466608),\n",
      "    ('policy', 0.008513626),\n",
      "    ('time', 0.008394788),\n",
      "    ('experience', 0.0077690547),\n",
      "    ('associate', 0.0074534426),\n",
      "    ('incentive', 0.0069486867)]\n",
      "\n",
      "[   ('incentive', 0.011310308),\n",
      "    ('material', 0.011265695),\n",
      "    ('governance', 0.009750038),\n",
      "    ('program', 0.009293055),\n",
      "    ('business', 0.009154368),\n",
      "    ('time', 0.007775401),\n",
      "    ('believe', 0.0071546305),\n",
      "    ('store', 0.007015252),\n",
      "    ('measure', 0.006869569),\n",
      "    ('member', 0.006488482)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for company in names:\n",
    "    for i in range(ntopic):\n",
    "        pp.pprint(lda_walmart.show_topic(topicid=i))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Amazon',\n",
       "  <__main__.MyCorpus at 0x175fb1a2f28>,\n",
       "  <gensim.models.ldamodel.LdaModel at 0x175fb21e390>),\n",
       " ('Walmart',\n",
       "  <__main__.MyCorpus at 0x175fb18d320>,\n",
       "  <gensim.models.ldamodel.LdaModel at 0x175faec3f28>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_prod[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walmart model applied to Walmart documents\n",
      "[   (0.5750969839551383, 0),\n",
      "    (0.6567462415793367, 1),\n",
      "    (0.46689547139305804, 2),\n",
      "    (0.4433712647719817, 3),\n",
      "    (0.462936506491735, 4),\n",
      "    (0.4790720435708886, 5),\n",
      "    (0.37562689524410026, 6),\n",
      "    (0.4259581234158769, 7),\n",
      "    (0.5650457358206896, 8),\n",
      "    (0.5063072928142819, 9)]\n",
      "\n",
      "Walmart model applied to Amazon documents\n",
      "[   (0.45825801297443075, 0),\n",
      "    (0.15812429751488655, 1),\n",
      "    (0.19264146202275978, 2),\n",
      "    (0.2131068251193176, 3),\n",
      "    (0.13568668933585287, 4),\n",
      "    (0.16309470708171528, 5),\n",
      "    (0.07787389209603562, 6),\n",
      "    (0.06566434313676187, 7),\n",
      "    (0.27153033536711807, 8),\n",
      "    (0.2864854831229612, 9)]\n",
      "\n",
      "Walmart model applied to Costco documents\n",
      "[   (0.47039772111312145, 0),\n",
      "    (0.18984703453915083, 1),\n",
      "    (0.16073144665669378, 2),\n",
      "    (0.1693489032157627, 3),\n",
      "    (0.18867502465995178, 4),\n",
      "    (0.2093837199328871, 5),\n",
      "    (0.0680996984243393, 6),\n",
      "    (0.07958730074266593, 7),\n",
      "    (0.23288092675929267, 8),\n",
      "    (0.3021251380769084, 9)]\n",
      "\n",
      "Walmart model applied to Target documents\n",
      "[   (0.28246387367604653, 0),\n",
      "    (0.17656710625978259, 1),\n",
      "    (0.09464685835621574, 2),\n",
      "    (0.26103830830076, 3),\n",
      "    (0.15409454194732108, 4),\n",
      "    (0.17063178224322786, 5),\n",
      "    (0.10030684108589438, 6),\n",
      "    (0.08325891890754439, 7),\n",
      "    (0.22117534262258084, 8),\n",
      "    (0.2611855597602808, 9)]\n",
      "\n",
      "Walmart model applied to Kroger documents\n",
      "[   (0.26010167518113325, 0),\n",
      "    (0.16381308987992516, 1),\n",
      "    (0.11448822496220087, 2),\n",
      "    (0.1722641231075557, 3),\n",
      "    (0.11352729005309252, 4),\n",
      "    (0.16293257491702426, 5),\n",
      "    (0.130831619008855, 6),\n",
      "    (0.131923507750628, 7),\n",
      "    (0.19199138424588938, 8),\n",
      "    (0.35651973603366005, 9)]\n",
      "\n",
      "Amazon model applied to Walmart documents\n",
      "Fail to converge\n",
      "\n",
      "Amazon model applied to Amazon documents\n",
      "[   (0.5548199766781181, 0),\n",
      "    (0.5318777982378379, 1),\n",
      "    (0.8185805739978185, 2),\n",
      "    (0.7126924334601923, 3),\n",
      "    (0.5319339409770985, 4),\n",
      "    (0.5637939476053899, 5),\n",
      "    (0.6921302778172796, 6),\n",
      "    (0.5197155956664811, 7),\n",
      "    (0.6086299061425962, 8),\n",
      "    (0.7379828423070602, 9)]\n",
      "\n",
      "Amazon model applied to Costco documents\n",
      "[   (0.11395283863402722, 0),\n",
      "    (0.18539816719528876, 1),\n",
      "    (0.12284993533311146, 2),\n",
      "    (0.28076553526019604, 3),\n",
      "    (0.2875441886018962, 4),\n",
      "    (0.23750480221233505, 5),\n",
      "    (0.19355872136440652, 6),\n",
      "    (0.21153739895099463, 7),\n",
      "    (0.1746996483911496, 8),\n",
      "    (0.1549131036499294, 9)]\n",
      "\n",
      "Amazon model applied to Target documents\n",
      "Fail to converge\n",
      "\n",
      "Amazon model applied to Kroger documents\n",
      "Fail to converge\n",
      "\n",
      "Costco model applied to Walmart documents\n",
      "Fail to converge\n",
      "\n",
      "Costco model applied to Amazon documents\n",
      "Fail to converge\n",
      "\n",
      "Costco model applied to Costco documents\n",
      "[   (0.495108079643467, 0),\n",
      "    (0.5379367230110802, 1),\n",
      "    (0.5872821364318952, 2),\n",
      "    (0.7283080716648799, 3),\n",
      "    (0.6751687491957384, 4),\n",
      "    (0.5199783465100659, 5),\n",
      "    (0.5975431014209035, 6),\n",
      "    (0.5307520960923284, 7),\n",
      "    (0.6690935499474897, 8),\n",
      "    (0.6704636458889581, 9)]\n",
      "\n",
      "Costco model applied to Target documents\n",
      "Fail to converge\n",
      "\n",
      "Costco model applied to Kroger documents\n",
      "Fail to converge\n",
      "\n",
      "Target model applied to Walmart documents\n",
      "Fail to converge\n",
      "\n",
      "Target model applied to Amazon documents\n",
      "[   (0.11979368250883583, 0),\n",
      "    (0.33573411452358193, 1),\n",
      "    (0.17562547518561283, 2),\n",
      "    (0.2559656652909024, 3),\n",
      "    (0.22666518135507285, 4),\n",
      "    (0.1636197596336856, 5),\n",
      "    (0.21174313619013618, 6),\n",
      "    (0.20685374309067373, 7),\n",
      "    (0.07143000947932403, 8),\n",
      "    (0.11107092261469613, 9)]\n",
      "\n",
      "Target model applied to Costco documents\n",
      "[   (0.13755860146861407, 0),\n",
      "    (0.30684609671588986, 1),\n",
      "    (0.12255933491937947, 2),\n",
      "    (0.16380298617142405, 3),\n",
      "    (0.21054102746251074, 4),\n",
      "    (0.20838580556489802, 5),\n",
      "    (0.2763137715663445, 6),\n",
      "    (0.27848165681459297, 7),\n",
      "    (0.06562716327607632, 8),\n",
      "    (0.14664433050202205, 9)]\n",
      "\n",
      "Target model applied to Target documents\n",
      "[   (0.4580725101479048, 0),\n",
      "    (0.646121756144824, 1),\n",
      "    (0.4889235002782058, 2),\n",
      "    (0.43163192223437363, 3),\n",
      "    (0.48793035369966453, 4),\n",
      "    (0.45324620404693333, 5),\n",
      "    (0.6375905468289531, 6),\n",
      "    (0.4967323848003045, 7),\n",
      "    (0.45403257591117707, 8),\n",
      "    (0.5067942786522003, 9)]\n",
      "\n",
      "Target model applied to Kroger documents\n",
      "Fail to converge\n",
      "\n",
      "Kroger model applied to Walmart documents\n",
      "Fail to converge\n",
      "\n",
      "Kroger model applied to Amazon documents\n",
      "[   (0.08960107984867963, 0),\n",
      "    (0.1765112904887535, 1),\n",
      "    (0.138679668086728, 2),\n",
      "    (0.27511456404768286, 3),\n",
      "    (0.23988695883867786, 4),\n",
      "    (0.2894944442010551, 5),\n",
      "    (0.11887511863498036, 6),\n",
      "    (0.29632765371691094, 7),\n",
      "    (0.2145043528505734, 8),\n",
      "    (0.10707656968046318, 9)]\n",
      "\n",
      "Kroger model applied to Costco documents\n",
      "[   (0.09260749087358515, 0),\n",
      "    (0.1570944289477276, 1),\n",
      "    (0.16837907098581859, 2),\n",
      "    (0.13157522769482888, 3),\n",
      "    (0.18536252068440776, 4),\n",
      "    (0.23466720373494132, 5),\n",
      "    (0.13393607339326372, 6),\n",
      "    (0.40137584870141607, 7),\n",
      "    (0.2063322494493671, 8),\n",
      "    (0.11603098995280715, 9)]\n",
      "\n",
      "Kroger model applied to Target documents\n",
      "[   (0.1079810470615959, 0),\n",
      "    (0.15214272296659395, 1),\n",
      "    (0.12451696527431479, 2),\n",
      "    (0.12113938902161624, 3),\n",
      "    (0.29366073154869976, 4),\n",
      "    (0.21217723789338308, 5),\n",
      "    (0.1275458724696341, 6),\n",
      "    (0.3230434408009189, 7),\n",
      "    (0.18982998723447714, 8),\n",
      "    (0.16080321038536954, 9)]\n",
      "\n",
      "Kroger model applied to Kroger documents\n",
      "[   (0.5821564989559578, 0),\n",
      "    (0.5120511141279315, 1),\n",
      "    (0.5003052525726599, 2),\n",
      "    (0.47377005615694956, 3),\n",
      "    (0.4372997209893085, 4),\n",
      "    (0.5764504222588688, 5),\n",
      "    (0.5828560284224519, 6),\n",
      "    (0.5559902329552026, 7),\n",
      "    (0.4676748450680826, 8),\n",
      "    (0.4937945641137941, 9)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "for index, pair in enumerate(names_prod):\n",
    "    model_txt  = pair[0][0]\n",
    "    corpus_txt = pair[1][0]\n",
    "    \n",
    "    model  = pair[0][2]\n",
    "    corpus = pair[1][1]\n",
    "    \n",
    "    print(f\"{model_txt} model applied to {corpus_txt} documents\")\n",
    "    \n",
    "    try:\n",
    "        tag = [model.get_document_topics(item) for item in corpus]\n",
    "        tag = [tup[::-1] for tup in flatten(tag)]\n",
    "\n",
    "        topic_avg = average_topic(tag)\n",
    "        topic_avg = sorted(topic_avg, key = lambda x: x[1])\n",
    "\n",
    "        pp.pprint(topic_avg)\n",
    "    except:\n",
    "        print(\"Fail to converge\")\n",
    "        \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
